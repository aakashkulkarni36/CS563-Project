@inproceedings{7467300,
  author    = {Youm, Klaus Changsun and Ahn, June and Kim, Jeongho and Lee, Eunseok},
  booktitle = {2015 Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {Bug Localization Based on Code Change Histories and Bug Reports},
  year      = {2015},
  pages     = {190-197},
  keywords  = {History;Computer bugs;Information retrieval;Software maintenance;Indexes;Data mining;bug localization;fault localization;information retrieval;bug report;stack traces;code change history},
  doi       = {10.1109/APSEC.2015.23}
}



@inproceedings{8367068,
  author    = {Ribeiro, Henrique L. and de Araujo, Roberto P. A. and Chaim, Marcos L. and de Souza, Higor A. and Kon, Fabio},
  booktitle = {2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)},
  title     = {Jaguar: A Spectrum-Based Fault Localization Tool for Real-World Software},
  year      = {2018},
  pages     = {404-409},
  keywords  = {Tools;Measurement;Debugging;Computer bugs;Java;Testing;Task analysis;Fault localization;Spectrum based;Debugging;Tool;Structural testing;Data flow;Control-flow;Tests},
  doi       = {10.1109/ICST.2018.00048}
}



@article{automatedTestTaxonomy,
  author  = {Marculescu, Bogdan and Zhang, Man and Arcuri, Andrea},
  year    = {2022},
  month   = {07},
  pages   = {1-43},
  title   = {On the Faults Found in REST APIs by Automated Test Generation},
  volume  = {31},
  journal = {ACM Transactions on Software Engineering and Methodology},
  doi     = {10.1145/3491038}
}

@article{app12094369,
  author         = {Ehsan, Adeel and Abuhaliqa, Mohammed Ahmad M. E. and Catal, Cagatay and Mishra, Deepti},
  title          = {RESTful API Testing Methodologies: Rationale, Challenges, and Solution Directions},
  journal        = {Applied Sciences},
  volume         = {12},
  year           = {2022},
  number         = {9},
  article-number = {4369},
  url            = {https://www.mdpi.com/2076-3417/12/9/4369},
  issn           = {2076-3417},
  abstract       = {Service-oriented architecture has evolved to be the backbone for large-scale integration between different applications and platforms. This concept has led to today’s reality of cloud services. Many of the major business platforms are providing their services to end-users and other companies as well. Companies are crafting ways to allow other businesses fast service integration and to get on board quickly in the market. REST (representational state transfer) has emerged as the standard protocol for implementing and consuming these services, which are called RESTful application programming interfaces (APIs). As the internal details of the RESTful APIs are not completely available during consumption, thorough testing has been a major challenge. Any unprecedented change in the APIs can cause the major failure of service operations, which can cause an organization to face both financial and trust losses. Research efforts have been made to alleviate testing challenges by introducing different frameworks and auto-generating unit test approaches. However, there is still a lack of an overview of the state-of-the-art in RESTful API testing. As such, the objective of this article is to identify, analyze, and synthesize the studies that have been performed related to RESTful APIs’ testing methodologies and unit test generation. With this perspective, a systematic literature review (SLR) study was conducted. In total, 16 papers were retrieved and included based on study selection criteria for in-depth analysis. This SLR discusses and categorizes different problems and solutions related to RESTful APIs’ testing and unit test generation.},
  doi            = {10.3390/app12094369}
}


@article{ctx114059874780001451,
  lccn      = {2003233427},
  publisher = {Elsevier Science},
  title     = {Improved bug localization based on code change histories and bug reports},
  volume    = {82},
  year      = {2017},
  author    = {Youm, Klaus Changsun and Ahn, June and Lee, Eunseok},
  address   = {[Amsterdam] :},
  issn      = {09505849},
  journal   = {Information and Software Technology}
}


@inbook{DebuggingCode,
  isbn      = {9781119588238},
  title     = {Debugging Code},
  isbn      = {9781119588238},
  booktitle = {Visual Studio Code},
  doi       = {https://doi.org/10.1002/9781119588238.ch6},
  year      = {2019},
  keywords  = {breakpoints, data inspection, debugger extensions, debugging code, Node.js applications, Visual Studio Code, web application}
}


@inbook{Wong2023_Software_Fault_localization,
  author   = {Wong, W. Eric and Gao, Ruizhi and Li, Yihao and Abreu, Rui and Wotawa, Franz and Li, Dongcheng},
  isbn     = {9781119880929},
  title    = {Software Fault Localization: an Overview of Research, Techniques, and Tools},
  year     = {2023},
  keywords = {advanced fault localization techniques, software fault localization tools, subject programs, traditional fault localization techniques}
}


@article{li2016,
  title   = {Design Patterns and Extensibility of REST API for Networking Applications},
  author  = {Li, L. and Chou, W. and Zhou, W. and Luo, M.},
  journal = {IEEE Transactions on Network and Service Management},
  volume  = {13},
  pages   = {154--167},
  year    = {2016}
}

@article{neumann2018,
  title   = {An Analysis of Public REST Web Service APIs},
  author  = {Neumann, A. and Laranjeiro, N. and Bernardino, J.},
  journal = {IEEE Transactions on Services Computing},
  volume  = {14},
  pages   = {957--970},
  year    = {2018}
}

@inproceedings{pahl2016,
  title     = {Microservices: A Systematic Mapping Study},
  author    = {Pahl, C. and Jamshidi, P.},
  booktitle = {Proceedings of the 6th International Conference on Cloud Computing and Services Science},
  pages     = {137--146},
  location  = {Rome, Italy},
  year      = {2016}
}

@inproceedings{khare2004,
  title     = {Extending the Representational State Transfer (REST) architectural style for decentralized systems},
  author    = {Khare, R. and Taylor, R.},
  booktitle = {Proceedings of the 26th International Conference on Software Engineering},
  pages     = {428--437},
  location  = {Edinburgh, UK},
  year      = {2004}
}


@incollection{barbir2007,
  title     = {Challenges of testing web services and security in SOA implementations},
  author    = {Barbir, A. and Hobbs, C. and Bertino, E. and Hirsch, F. and Martino, L.},
  booktitle = {Test and Analysis of Web Services},
  pages     = {395--440},
  publisher = {Springer},
  address   = {Berlin/Heidelberg, Germany},
  year      = {2007}
}


@inproceedings{ed-douibi2018,
  title={OpenAPItoUML: A tool to generate UML models from OpenAPI definitions},
  author={Ed-Douibi, H. and Izquierdo, J.L.C. and Cabot, J.},
  booktitle={International Conference on Web Engineering},
  pages={487--491},
  publisher={Springer},
  address={Cham, Switzerland},
  location={Cáceres, Spain},
  year={2018}
}

@inproceedings{ManishRestServices,
author = {Huang, Ruikai and Motwani, Manish and Martinez, Idel and Orso, Alessandro},
title = {Generating REST API Specifications through Static Analysis},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639137},
doi = {10.1145/3597503.3639137},
abstract = {Web Application Programming Interfaces (APIs) allow services to be accessed over the network. RESTful (or REST) APIs, which use the REpresentation State Transfer (REST) protocol, are a popular type of web API. To use or test REST APIs, developers use specifications written in standards such as OpenAPI. However, creating and maintaining these specifications is time-consuming and error-prone, especially as software evolves, leading to incomplete or inconsistent specifications that negatively affect the use and testing of the APIs. To address this problem, we present Respector (REST API specification generator), the first technique to employ static and symbolic program analysis to generate specifications for REST APIs from their source code. We evaluated Respector on 15 real-world APIs with promising results in terms of precision and recall in inferring endpoint methods, endpoint parameters, method responses, and parameter attributes, including constraints leading to successful HTTP responses or errors. Furthermore, these results could be further improved with additional engineering. Comparing the Respector-generated specifications with the developer-provided ones shows that Respector was able to identify many missing end-point methods, parameters, constraints, and responses, along with some inconsistencies between developer-provided specifications and API implementations. Finally, Respector outperformed several techniques that infer specifications from annotations within API implementations or by invoking the APIs.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {107},
numpages = {13},
keywords = {REST APIs, openapi specifications, documentation, static analysis},
series = {ICSE '24}
}


@inproceedings{ManishBluesFaultLocalization,
author = {Motwani, Manish and Brun, Yuriy},
title = {Better Automatic Program Repair by Using Bug Reports and Tests Together},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00109},
doi = {10.1109/ICSE48619.2023.00109},
abstract = {Automated program repair is already deployed in industry, but concerns remain about repair quality. Recent research has shown that one of the main reasons repair tools produce incorrect (but seemingly correct) patches is imperfect fault localization (FL). This paper demonstrates that combining information from natural-language bug reports and test executions when localizing faults can have a significant positive impact on repair quality. For example, existing repair tools with such FL are able to correctly repair 7 defects in the Defects4J benchmark that no prior tools have repaired correctly.We develop, Blues, the first information-retrieval-based, statement-level FL technique that requires no training data. We further develop RAFL, the first unsupervised method for combining multiple FL techniques, which outperforms a supervised method. Using RAFL, we create SBIR by combining Blues with a spectrum-based (SBFL) technique. Evaluated on 815 real-world defects, SBIR consistently ranks buggy statements higher than its underlying techniques.We then modify three state-of-the-art repair tools, Arja, SequenceR, and SimFix, to use SBIR, SBFL, and Blues as their internal FL. We evaluate the quality of the produced patches on 689 real-world defects. Arja and SequenceR significantly benefit from SBIR: Arja using SBIR correctly repairs 28 defects, but only 21 using SBFL, and only 15 using Blues; SequenceR using SBIR correctly repairs 12 defects, but only 10 using SBFL, and only 4 using Blues. SimFix, (which has internal mechanisms to overcome poor FL), correctly repairs 30 defects using SBIR and SBFL, but only 13 using Blues. Our work is the first investigation of simultaneously using multiple software artifacts for automated program repair, and our promising findings suggest future research in this directions is likely to be fruitful.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
numpages = {13},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}


@inproceedings{LLMAOFaultLocalization,
author = {Yang, Aidan Z. H. and Le Goues, Claire and Martins, Ruben and Hellendoorn, Vincent},
title = {Large Language Models for Test-Free Fault Localization},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623342},
doi = {10.1145/3597503.3623342},
abstract = {Fault Localization (FL) aims to automatically localize buggy lines of code, a key first step in many manual and automatic debugging tasks. Previous FL techniques assume the provision of input tests, and often require extensive program analysis, program instrumentation, or data preprocessing. Prior work on deep learning for APR struggles to learn from small datasets and produces limited results on real-world programs. Inspired by the ability of large language models (LLMs) of code to adapt to new tasks based on very few examples, we investigate the applicability of LLMs to line level fault localization. Specifically, we propose to overcome the left-to-right nature of LLMs by fine-tuning a small set of bidirectional adapter layers on top of the representations learned by LLMs to produce LLMAO, the first language model based fault localization approach that locates buggy lines of code without any test coverage information. We fine-tune LLMs with 350 million, 6 billion, and 16 billion parameters on small, manually curated corpora of buggy programs such as the Defects4J corpus. We observe that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the LLM size. Our empirical evaluation shows that LLMAO improves the Top-1 results over the state-of-the-art machine learning fault localization (MLFL) baselines by 2.3\%--54.4\%, and Top-5 results by 14.4\%-35.6\%. LLMAO is also the first FL technique trained using a language model architecture that can detect security vulnerabilities down to the code line level.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {17},
numpages = {12},
series = {ICSE '24}
}